# -*- coding: utf-8 -*-
"""ML_Assignment_3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1orSgylghpJajWvsNGqKljtJoZs4KrdP2
"""

# Importing relevant libraries
#import scorecardpy as sc
import pandas as pd
import numpy as np
from sklearn import preprocessing
import matplotlib.pyplot as plt
#get_ipython().run_line_magic('matplotlib', 'inline')
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
import seaborn as sns

import matplotlib
print(matplotlib.__version__)

# Reading the dataset
df_bank = pd.read_csv('/content/bank-full.csv',sep=';')

#Checking the dataset
df_bank.head()

# Checking the shape of the dataframe
df_bank.shape

# Print the column names
print(list(df_bank.columns))

# Check the event rate
df_bank['y'].value_counts()/len(df_bank)

# Remove data with any missing information for now
df_bank = df_bank.dropna()

print(df_bank.shape)

"""# Basic Data Exploration"""

# Get summary stats for the categorical features
df_bank.describe(include = ['O'])

# check the summary of the dataframe
df_bank.describe()

# Create the feature/flag for Dep variable - Attrition status
df_bank.y = df_bank.y.apply(lambda x: 1 if x =='yes' else 0)

# Check the event rate
df_bank['y'].value_counts()/len(df_bank)

# Explore different features for any kind of inconsistent values
print('age:',sorted(df_bank.age.unique()))
print('job:',df_bank.job.unique())
print('marital:',df_bank.marital.unique())
print('education:',df_bank.education.unique())
print('default:',df_bank.default.unique())
print('housing:',df_bank.housing.unique())
print('loan:',df_bank.loan.unique())
print('contact:',df_bank.contact.unique())
print('day:',df_bank.day.unique())
print('month:',df_bank.month.unique())
print('duration:',df_bank.duration.unique())
print('campaign:',df_bank.campaign.unique())
print('poutcome:',df_bank.poutcome.unique())

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
pd.crosstab(df_bank.marital,df_bank.y).plot(kind='bar')
plt.title('Purchase Frequency based on marital status')
plt.xlabel('Job')
plt.ylabel('Purchase Freq')

df_bank.age.hist()
plt.title('Histogram of Age')
plt.xlabel('Age')
plt.ylabel('Freq')

# Convert the categorical features
# Creating dummies for all these variables
d_job = pd.get_dummies(df_bank['job'], prefix='job',drop_first=True,dtype=float)
d_education = pd.get_dummies(df_bank['education'],drop_first=True, prefix='edu',dtype=float)
d_default = pd.get_dummies(df_bank['default'],drop_first=True, prefix='def',dtype=float)
d_housing = pd.get_dummies(df_bank['housing'],drop_first=True, prefix='housing',dtype=float)
d_loan = pd.get_dummies(df_bank['loan'],drop_first=True, prefix='loan',dtype=float)
d_contact = pd.get_dummies(df_bank['contact'],drop_first=True, prefix='con',dtype=float)
d_poutcome = pd.get_dummies(df_bank['poutcome'],drop_first=True, prefix='pout',dtype=float)
d_marital = pd.get_dummies(df_bank['marital'],drop_first=True, prefix='marital',dtype=float)
d_month = pd.get_dummies(df_bank['month'],drop_first=True, prefix='mon',dtype=float)

# Create the final dataset with all the relevant features - both dependant and predictors
feature_x_cont = ['age','balance','duration','pdays','previous','campaign']
df_bank_cont = df_bank[feature_x_cont]

# Creating the Final data with all the relevant fields and Dep Variable
df_bank_new = pd.concat([d_job,d_education,d_default,d_housing,
                       d_loan,d_contact,d_poutcome,d_marital,d_month,
                       df_bank_cont,df_bank['y']],axis=1)

# Checking the shape of the resultane dataframe
df_bank_new.shape

# Checking the dataframe
df_bank_new.head()

"""# EDA"""

import pandas as pd

# Set display options for pandas to improve the readability of the output
#pd.set_option('display.width', 200)
#pd.set_option('precision', 2)

# Calculate Pearson correlation between 'balance' and 'campaign'
correlations = df_bank_new[['balance', 'campaign']].corr(method='pearson')

# Print the correlation matrix
print(correlations)

# Plotting Box Plot of Age by Status
df_bank_new.boxplot(column=['age'], return_type='axes', by='y')
plt.show()

# We can do some further EDA for a pool of features as well
subset_attributes = ['age', 'balance', 'campaign', 'duration','pdays','previous']
err_yes = round(df_bank_new[df_bank_new['y'] == 1][subset_attributes].describe(),2)
err_no = round(df_bank_new[df_bank_new['y'] == 0][subset_attributes].describe(),2)
pd.concat([err_yes, err_no], axis=1, keys=['y=1 ', 'y=0'])

# Inferential Stats
from scipy import stats
F, p = stats.f_oneway(df_bank_new[df_bank_new['y'] == 1]['balance'],
                      df_bank_new[df_bank_new['y'] == 0]['balance'])
print('ANOVA test for mean balance levels across y status')
print('F Statistic:', F, ' p-value:', p)

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline

# Univariate analysis
df_bank_new.hist(bins=10, color='purple', edgecolor='black', linewidth=1.0,
              xlabelsize=7, ylabelsize=8, grid=False)
plt.tight_layout(rect=(0, 0, 10, 10))
plt.show()
# plt.tight_layout()
rt = plt.suptitle('Bank data', x=0.9, y=2.25, fontsize=20)

# Finding the Correlation values for all the features
(round(df_bank_new.corr(),2))

# plotting the pair plot to check the relation between the columns
import seaborn as sns
cols = ['y','balance','age', 'pdays', 'duration','previous']
pp = sns.pairplot(df_bank_new[cols], hue='y', height=1.7, aspect=1.7,
                  plot_kws=dict(edgecolor="purple", linewidth=0.5))
fig = pp.fig
fig.subplots_adjust(top=0.93, wspace=0.3)
t = fig.suptitle('Subscription Status Pairwise Plots', fontsize=20)

"""# Building the Logistic Regression Classifier for the Bank data

# Feature Selection - Recursive Feature elimination
"""

# Assining the features and the target variable
Y_bank_data = df_bank_new['y']
X_bank_data = df_bank_new.drop(['y'],axis=1)

# Checking the shape of the training data
print(Y_bank_data.shape)
print(X_bank_data.shape)

# Creating the Feature Space for bank data
X_colnames_u = [cols for cols in df_bank_new.columns.tolist() if cols not in [
'y'
]]
X_colnames_u

# Scaling of Data
from sklearn.preprocessing import MinMaxScaler
SC = MinMaxScaler()
X = pd.DataFrame(SC.fit_transform(X_bank_data), columns = X_colnames_u)

X.head()

# Creating Training and Test data
x_train,x_test,y_train,y_test = train_test_split(X,Y_bank_data,train_size = 0.75,random_state=42)

print(x_train.shape)
print(x_test.shape)
print(y_train.shape)
print(y_test.shape)

# Function for logging
import warnings
warnings.filterwarnings("ignore")

import time
from datetime import datetime
def log_msg(message):
    print(str(datetime.now()) + ": " + message)

#log_msg("Started running LR for feature selection...")
from sklearn.feature_selection import RFE
from sklearn.linear_model import LogisticRegression
# from sklearn.feature_selection import RFE

lr1 = LogisticRegression(penalty='l2', tol=0.0001, C=0.003, fit_intercept=True, max_iter=200, verbose=1)
rfe = RFE(estimator=lr1, n_features_to_select=30, step=1)
rfe.fit(x_train, y_train)

#log_msg("Completed running LR for feature selection...")

#checking the features
select_features_rfe = rfe.get_support()
feature_names_rfe = X.columns[select_features_rfe]
print(feature_names_rfe)
set(feature_names_rfe)

cols=feature_names_rfe

list(cols)

print(select_features_rfe)

# Final Features
"""cls=['age',
 'balance',
 'campaign',
 'con_unknown',
 'duration',
 'edu_primary',
 'edu_secondary',
 'edu_tertiary',
 'housing_no',
 'housing_yes',
 'job_blue-collar',
 'job_management',
 'job_self-employed',
 'job_services',
 'job_student',
 'job_technician',
 'loan_no',
 'loan_yes',
 'marital_divorced',
 'marital_married',
 'marital_single',
 'mon_aug',
 'mon_jul',
 'mon_may',
 'mon_nov',
 'mon_sep',
 'pdays',
 'pout_failure',
 'pout_success',
 'previous']
x_new_f=df_bank_new[cols]
y_new_f=df_bank_new['y']"""

#Assigning the features and the target variable
x_new_f=df_bank_new[cols]
y_new_f=df_bank_new['y']

x_new_f

# encoding the target variable
y_new_f.replace(to_replace = ["yes","no"],value = [1,0], inplace = True)

y_new_f

print(x_new_f.shape)
print(y_new_f.shape)

x_new_f.head(2)

#splitting the data into train and test
x_train,x_test,y_train,y_test = train_test_split(x_new_f,y_new_f,train_size = 0.7,random_state=42)

#assigning the Logistic regressor
Lr_1=LogisticRegression()

# Model training by fitting the train data
Lr_1.fit(x_train,y_train)

# Predicting the results on the train and test data
y_predict_train=Lr_1.predict(x_train)
y_predict_test=Lr_1.predict(x_test)

"""Evaluation Matrix"""

from  sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score,classification_report

# Printing the confusion matrix
print(confusion_matrix(y_train,y_predict_train))
print(confusion_matrix(y_test,y_predict_test))

# Plotting the confusion matrix on train data
sns.heatmap((confusion_matrix(y_train,y_predict_train)),annot=True,fmt='.5g'
            ,cmap='Blues');
plt.xlabel('Predicted');
plt.ylabel('Actuals',rotation=0);
plt.title('CONFUSION MATRIX - CUT OFF (0.5)')

# Confusion matrix on the test data
sns.heatmap((confusion_matrix(y_test,y_predict_test)),annot=True,fmt='.5g'
            ,cmap='Blues');
plt.xlabel('Predicted');
plt.ylabel('Actuals',rotation=0);
plt.title('CONFUSION MATRIX - CUT OFF (0.5)')

# Accuracy score of the train and test data
acc_train=  accuracy_score(y_train,y_predict_train)
acc_test= accuracy_score(y_test,y_predict_test)
print("train_accuracy",acc_train)

print("test_accuracy",acc_test)

#Recall score of the train and test data
recall_train=recall_score(y_train,y_predict_train)
recall_test=recall_score(y_test,y_predict_test)
print("train_recall",recall_train)

print("test_recall",recall_test)

# Precision Score of the train and test data
prec_train=precision_score(y_train,y_predict_train)
prec_test=precision_score(y_test,y_predict_test)
print("train_prec",prec_train)

print("test_prec",prec_test)

# F1 score of the train and test data
f1_train=f1_score(y_train,y_predict_train)
f1_test=f1_score(y_test,y_predict_test)
print("f1_train",f1_train)
print("f1_test",f1_test)

# Printing the metrics on train data
print(classification_report(y_train,y_predict_train))

# Printing the metrics on the test data
print(classification_report(y_test,y_predict_test))





















